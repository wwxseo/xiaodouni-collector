import os
import re
import requests
import time
from bs4 import BeautifulSoup

def get_xiaodouni_images():
    """ä» Bing æœç´¢æŠ“å–é«˜æ¸…å°è±†æ³¥å›¾ç‰‡"""
    print("ğŸš€ æ­£åœ¨æœå¯»é«˜æ¸…å¤§å›¾ç‰ˆæœ¬çš„å°è±†æ³¥...")
    
    # æœç´¢è¯å¢åŠ äº†â€œé«˜æ¸…å£çº¸â€ï¼Œå¹¶åŠ å…¥äº† qft=+filterui:imagesize-large å‚æ•°ï¼Œå¼ºåˆ¶åªæœå¤§å›¾
    query = "å°è±†æ³¥ é«˜æ¸…å£çº¸"
    url = f"https://www.bing.com/images/search?q={query}&qft=+filterui:imagesize-large&form=IRFLTR"
    
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36",
        "Accept-Language": "zh-CN,zh;q=0.9"
    }
    
    try:
        response = requests.get(url, headers=headers, timeout=20)
        response.raise_for_status()
        # ç¨å¾®ç­‰ä¸€ä¸‹ï¼Œç¡®ä¿è§£ææ²¡å‹åŠ›
        time.sleep(1)
        
        soup = BeautifulSoup(response.text, 'html.parser')
        images = []
        
        # å¯»æ‰¾å¸¦æœ‰ m å±æ€§çš„èŠ‚ç‚¹
        for img_tag in soup.find_all("a", class_="iusc"):
            m_content = img_tag.get("m")
            if m_content:
                # æå– murl (åŸå§‹å›¾ç‰‡åœ°å€)
                murl_match = re.search(r'"murl":"(.*?)"', m_content)
                if murl_match:
                    img_url = murl_match.group(1)
                    
                    # è¿‡æ»¤æ‰ä¸€äº›æ˜æ˜¾çš„ä½è´¨å›¾æºæˆ–å¤´åƒåº“ï¼ˆå¯é€‰ï¼‰
                    if any(exclude in img_url for exclude in ["thumbnail", "avatar", "100x100"]):
                        continue
                        
                    images.append(img_url)
            
            # æŠ“å– 12 å¼ é«˜æ¸…å›¾ï¼Œæ’ç‰ˆæ›´ç¾è§‚
            if len(images) >= 12: 
                break
        
        if not images:
            print("âš ï¸ æœªæ‰¾åˆ°é«˜æ¸…å›¾ç‰‡ï¼Œå°è¯•æ‰©å¤§æœç´¢èŒƒå›´...")
            # å¦‚æœå¤§å›¾æ²¡æœåˆ°ï¼Œè¿™é‡Œå¯ä»¥åšä¸€ä¸ªå¤‡é€‰é€»è¾‘ï¼Œä½†é€šå¸¸é«˜æ¸…å£çº¸è¯æ¡èƒ½æœåˆ°å¾ˆå¤š
        
        print(f"âœ… æˆåŠŸæ•è· {len(images)} å¼ é«˜æ¸…å°è±†æ³¥ï¼")
        return images
    except Exception as e:
        print(f"âŒ æŠ“å–è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        return []

def update_readme(urls):
    """æ›´æ–° README.md ä¸­çš„å›¾ç‰‡å¢™"""
    if not urls:
        return

    if not os.path.exists("README.md"):
        print("âš ï¸ æœªæ‰¾åˆ° README.md")
        return

    with open("README.md", "r", encoding="utf-8") as f:
        content = f.read()

    # æ„å»º HTML å›¾ç‰‡å¢™
    img_html = '<div align="center">\n'
    for url in urls:
        # ç»™å›¾ç‰‡åŠ ä¸€ä¸ªç®€å•çš„é˜´å½±å’Œæ‚¬åœæ•ˆæœï¼ˆé€šè¿‡ HTML æ¨¡æ‹Ÿï¼‰
        # width="180" ç•¥å¾®æ”¾å¤§ä¸€ç‚¹ï¼Œå±•ç¤ºæ¸…æ™°åº¦
        img_html += f'  <img src="{url}" width="180" alt="å°è±†æ³¥" style="margin:8px; border-radius:12px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">'
    img_html += '\n  <p><i>ğŸ”„ æ¯æ—¥è‡ªåŠ¨æ›´æ–°ï¼Œæœé›†è‡ªå…¨ç½‘é«˜æ¸…å›¾æº</i></p>\n</div>'
    
    pattern = r"<!-- START_SECTION:xiaodouni -->.*?<!-- END_SECTION:xiaodouni -->"
    replacement = f"<!-- START_SECTION:xiaodouni -->\n{img_html}\n<!-- END_SECTION:xiaodouni -->"
    
    new_content = re.sub(pattern, replacement, content, flags=re.DOTALL)

    with open("README.md", "w", encoding="utf-8") as f:
        f.write(new_content)
    print("âœ¨ README é«˜æ¸…ç¾å›¾å¢™å·²ç¿»æ–°ï¼")

if __name__ == "__main__":
    image_list = get_xiaodouni_images()
    update_readme(image_list)
