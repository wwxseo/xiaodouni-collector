import os
import re
import requests
from bs4 import BeautifulSoup

def get_xiaodouni_images():
    print("ğŸš€ å¼€å§‹æœå¯»å°è±†æ³¥...")
    search_urls = [
        "https://www.bing.com/images/search?q=å°è±†æ³¥+wallpaper&qft=+filterui:imagesize-large&form=IRFLTR",
        "https://www.bing.com/images/search?q=å°è±†æ³¥"
    ]
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36"
    }
    images = []
    for url in search_urls:
        if len(images) >= 12: break
        try:
            response = requests.get(url, headers=headers, timeout=15)
            soup = BeautifulSoup(response.text, 'html.parser')
            for img_tag in soup.find_all("a", class_="iusc"):
                m_content = img_tag.get("m")
                if m_content:
                    murl_match = re.search(r'"murl":"(.*?)"', m_content)
                    if murl_match:
                        img_url = murl_match.group(1)
                        if img_url.startswith("http") and img_url not in images:
                            images.append(img_url)
                if len(images) >= 12: break
        except: continue
    print(f"ğŸ¯ æœ€ç»ˆæ•è·å°è±†æ³¥æ•°é‡: {len(images)}")
    return images

def update_readme(urls):
    if not urls:
        print("âš ï¸ æœªæ‰¾åˆ°å›¾ç‰‡ï¼Œè·³è¿‡ã€‚")
        return
    
    with open("README.md", "r", encoding="utf-8") as f:
        content = f.read()

    img_html = '<div align="center">\n'
    for url in urls:
        img_html += f'  <img src="{url}" width="180" alt="å°è±†æ³¥" style="margin:5px; border-radius:12px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">'
    img_html += '\n  <p><i>ğŸ”„ æ¯æ—¥è‡ªåŠ¨æ›´æ–°ï¼Œæœé›†è‡ªå…¨ç½‘é«˜æ¸…å›¾æº</i></p>\n</div>'
    
    # æ›´åŠ å®½æ¾çš„æ­£åˆ™åŒ¹é…ï¼Œå…è®¸æ ‡è®°å†…éƒ¨æœ‰ç©ºæ ¼
    start_tag = "<!-- START_SECTION:xiaodouni -->"
    end_tag = "<!-- END_SECTION:xiaodouni -->"
    
    if start_tag in content and end_tag in content:
        print("âœ… æ‰¾åˆ°æ ‡è®°ï¼Œæ­£åœ¨æ›¿æ¢å†…å®¹...")
        pattern = r"<!-- START_SECTION:xiaodouni -->.*?<!-- END_SECTION:xiaodouni -->"
        replacement = f"{start_tag}\n{img_html}\n{end_tag}"
        new_content = re.sub(pattern, replacement, content, flags=re.DOTALL)
    else:
        print("âš ï¸ æœªæ‰¾åˆ°æ ‡å‡†æ ‡è®°ï¼Œå°†åœ¨æ–‡ä»¶æœ«å°¾è¿½åŠ å†…å®¹...")
        new_content = content + f"\n\n{start_tag}\n{img_html}\n{end_tag}"

    with open("README.md", "w", encoding="utf-8") as f:
        f.write(new_content)
    print("âœ¨ README å·²æ›´æ–°ï¼")

if __name__ == "__main__":
    image_list = get_xiaodouni_images()
    update_readme(image_list)
