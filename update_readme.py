import os
import re
import requests
import random
import time
from datetime import datetime
from urllib.parse import quote

# --- 1. é…ç½®åŒºåŸŸ ---

# å…³é”®è¯ï¼šå †ç³–ä¸Šçš„çƒ­é—¨æ ‡ç­¾
KEYWORDS = ["å°è±†æ³¥", "funny bean", "å°è±†æ³¥å¤´åƒ", "å°è±†æ³¥å£çº¸", "å°è±†æ³¥è¡¨æƒ…åŒ…"]

# --- 2. å·¥å…·å‡½æ•° ---

def get_seen_urls():
    """ä» history.md åŠ è½½è®°å¿†ï¼Œä½¿ç”¨æ–‡ä»¶åè¿›è¡ŒæŒ‡çº¹è¯†åˆ«ï¼Œå»é‡æ›´ç‹ """
    seen = set()
    if os.path.exists("history.md"):
        try:
            with open("history.md", "r", encoding="utf-8") as f:
                content = f.read()
                # æå–é“¾æ¥
                urls = re.findall(r'url=(http[^"\'&\s]+)', content)
                for u in urls:
                    seen.add(u)
                    # é¢å¤–æå–æ–‡ä»¶åä½œä¸ºæŒ‡çº¹
                    filename = u.split('/')[-1].split('?')[0]
                    if len(filename) > 5:
                        seen.add(filename)
        except Exception:
            pass
    print(f"ğŸ“œ è®°å¿†åº“åŠ è½½å®Œæ¯•ï¼ŒåŒ…å« {len(seen)} ä¸ªæŒ‡çº¹ã€‚")
    return seen

def wrap_proxy(url):
    """åŠ ä¸Š wsrv.nl ä»£ç†ï¼Œä¿®å¤é˜²ç›—é“¾ï¼Œç»Ÿä¸€è£å‰ª"""
    # æ¸…æ´—é“¾æ¥
    url = url.replace(r'\/', '/')
    encoded_url = quote(url, safe='')
    return f"https://wsrv.nl/?url={encoded_url}&w=300&h=300&fit=cover&bg=white&output=jpg"

# --- 3. æ ¸å¿ƒæŠ“å–é€»è¾‘ï¼šå †ç³– API ---

def fetch_from_duitang(needed, seen_fingerprints):
    print("ğŸš€ æ­£åœ¨æ½œå…¥å †ç³–å›¾åº“ (Duitang)...")
    images = []
    
    kw = random.choice(KEYWORDS)
    # éšæœºç¿»é¡µç­–ç•¥ï¼š0-50é¡µéšæœºè·³ä¼
    start_page = random.randint(0, 50) 
    start_index = start_page * 24
    
    print(f"ğŸ” å…³é”®è¯: [{kw}] | éšæœºç©ºé™è‡³ç¬¬ {start_page} é¡µ...")

    api_url = f"https://www.duitang.com/napi/blog/list/by_search/?kw={kw}&start={start_index}&limit=100"
    
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
        "Referer": "https://www.duitang.com/search/?kw=" + quote(kw)
    }

    try:
        resp = requests.get(api_url, headers=headers, timeout=10)
        data = resp.json()
        object_list = data.get('data', {}).get('object_list', [])
        
        if not object_list:
            print("âš ï¸ å½“å‰é¡µæ²¡æ•°æ®ï¼Œå¯èƒ½æ˜¯ç¿»é¡µç¿»å¤ªæ·±äº†ã€‚")
            return []

        random.shuffle(object_list)

        for item in object_list:
            img_url = item.get('photo', {}).get('path')
            if not img_url: continue
            
            # å»é‡
            if img_url in seen_fingerprints: continue
            filename = img_url.split('/')[-1]
            if filename in seen_fingerprints: continue
            
            images.append(img_url)
            if len(images) >= needed: break
            
    except Exception as e:
        print(f"âŒ è¿æ¥å †ç³–å¤±è´¥: {e}")
    
    return images

# --- 4. ä¸»æµç¨‹ ---

def get_all_images():
    seen = get_seen_urls()
    final_images = []
    
    attempts = 0
    while len(final_images) < 12 and attempts < 3:
        needed = 12 - len(final_images)
        new_batch = fetch_from_duitang(needed, seen)
        
        for img in new_batch:
            final_images.append(img)
            seen.add(img)
            seen.add(img.split('/')[-1])
            
        attempts += 1
        if len(final_images) < 12:
            time.sleep(1)

    print(f"ğŸ¯ æœ€ç»ˆæ•è· {len(final_images)} å¼ ç¨€æœ‰å›¾ç‰‡")
    return [wrap_proxy(img) for img in final_images]

def update_files(urls):
    if not urls:
        print("âŒ é¢—ç²’æ— æ”¶ï¼Œä»Šå¤©ä¼‘æ¯ã€‚")
        return

    # 1. æ›´æ–° README (å§‹ç»ˆå±•ç¤ºæœ€æ–°çš„)
    img_html = '<div align="center">\n'
    for url in urls:
        img_html += f'  <img src="{url}" width="160" height="160" alt="å°è±†æ³¥" style="margin:4px; border-radius:12px; object-fit:cover; box-shadow: 0 4px 12px rgba(0,0,0,0.1);">'
    img_html += '\n  <p><i>ğŸ§¶ å›¾ç‰‡é‡‡é›†è‡ªå †ç³–ç¤¾åŒºï¼Œæ¯æ—¥éšæœºæŒ–æ˜</i></p>\n</div>'

    if os.path.exists("README.md"):
        with open("README.md", "r", encoding="utf-8") as f:
            content = f.read()
        
        s_tag = "<!-- START_SECTION:xiaodouni -->"
        e_tag = "<!-- END_SECTION:xiaodouni -->"
        
        if s_tag in content and e_tag in content:
            s = content.find(s_tag) + len(s_tag)
            e = content.find(e_tag)
            new_content = content[:s] + "\n" + img_html + "\n" + content[e:]
            with open("README.md", "w", encoding="utf-8") as f:
                f.write(new_content)
        else:
            with open("README.md", "w", encoding="utf-8") as f:
                f.write(f"# å°è±†æ³¥æ”¶é›†å™¨\n\n{s_tag}\n{img_html}\n{e_tag}")
        print("âœ… README æ›´æ–°å®Œæˆ")

    # 2. æ›´æ–° History (å€’åºæ’å…¥)
    today = datetime.now().strftime("%Y-%m-%d %H:%M") # ç²¾ç¡®åˆ°åˆ†é’Ÿï¼Œæ–¹ä¾¿ä¸€å¤©è·‘å¤šæ¬¡åŒºåˆ†
    header = "# ğŸ“š å°è±†æ³¥å†å²æ”¶è—é¦†\n\nè¿™é‡Œè®°å½•äº†è‡ªæœ¬é¡¹ç›®å¯åŠ¨ä»¥æ¥æŠ“å–è¿‡çš„æ‰€æœ‰å›¾ç‰‡ã€‚\n\n---\n"
    
    # æ„å»ºä»Šæ—¥çš„æ–°å†…å®¹å—
    new_block = f"\n### ğŸ“… {today}\n<div align='left'>\n"
    for url in urls:
        new_block += f'  <img src="{url}" width="100" height="100" style="margin:2px; border-radius:6px; object-fit:cover;">\n'
    new_block += "</div>\n\n---\n"

    # è¯»å–æ—§æ–‡ä»¶å†…å®¹
    old_content = ""
    if os.path.exists("history.md"):
        with open("history.md", "r", encoding="utf-8") as f:
            content = f.read()
            # å¦‚æœæ–‡ä»¶é‡Œå·²ç»æœ‰æ ‡é¢˜ï¼Œå»æ‰å®ƒï¼Œåªä¿ç•™åé¢çš„è®°å½•ï¼Œé˜²æ­¢æ ‡é¢˜é‡å¤
            if content.strip().startswith("# ğŸ“š"):
                # å°è¯•æ‰¾åˆ°ç¬¬ä¸€ä¸ªåˆ†å‰²çº¿ï¼Œåˆ†å‰²çº¿ä¹‹åçš„å°±æ˜¯æ—§è®°å½•
                parts = content.split("---\n", 1)
                if len(parts) > 1:
                    old_content = parts[1]
                else:
                    # å¦‚æœæ‰¾ä¸åˆ°åˆ†å‰²çº¿ï¼Œè¯´æ˜æ–‡ä»¶å¯èƒ½åªæœ‰æ ‡é¢˜ï¼Œæˆ–è€…æ ¼å¼ä¹±äº†ï¼Œç›´æ¥ä½œä¸ºæ—§å†…å®¹
                    old_content = content.replace(header, "")
            else:
                old_content = content

    # æ‹¼æ¥ï¼šæ ‡é¢˜ + æ–°å†…å®¹ + æ—§å†…å®¹
    final_history = header + new_block + old_content
    
    with open("history.md", "w", encoding="utf-8") as f:
        f.write(final_history)
    print("âœ… History å½’æ¡£å®Œæˆ (å·²å€’åº)")

if __name__ == "__main__":
    imgs = get_all_images()
    update_files(imgs)
